{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkyUhl1g0JWf"
      },
      "source": [
        "## Import Library\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=pd.read_csv('IBM-3.csv')\n",
        "a.drop(columns=['7_day_std',\n",
        "       '7_SMA', '14_EMA', 'DMI_plus', 'DMI_minus', 'ATR', 'MACD',\n",
        "       'MACD_Signal', 'stoch_k', 'stoch_d', 'close_change'], inplace=True)\n",
        "a['Unnamed: 0'] = pd.to_datetime(a['Unnamed: 0'])\n",
        "a.set_index('Unnamed: 0', inplace=True)\n",
        "print(a)\n",
        "a = a[a.index.isin(df.index)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SWUPsdB-ghT",
        "outputId": "9a8263b2-0bea-4c35-8198-303f0dab0042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              open      high       low   close    volume\n",
            "Unnamed: 0                                              \n",
            "1999-11-01   98.50   98.8100   96.3700   96.75   9551800\n",
            "1999-11-02   96.75   96.8100   93.6900   94.81  11105400\n",
            "1999-11-03   95.87   95.9400   93.5000   94.37  10369100\n",
            "1999-11-04   94.44   94.4400   90.0000   91.56  16697600\n",
            "1999-11-05   92.75   92.9400   90.1900   90.25  13737600\n",
            "...            ...       ...       ...     ...       ...\n",
            "2024-11-04  207.65  207.7000  205.8000  206.32   2594119\n",
            "2024-11-05  206.17  208.1150  205.5700  207.57   2441535\n",
            "2024-11-06  213.48  214.3300  210.3700  213.60   3934386\n",
            "2024-11-07  213.64  214.5199  211.9300  213.69   3675812\n",
            "2024-11-08  214.16  216.7000  212.7809  213.72   3201038\n",
            "\n",
            "[6297 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import explained_variance_score\n",
        "dat=pd.read_csv('exog.csv')\n",
        "diff=pd.read_csv('diff.csv')\n",
        "df=dat.dropna()\n",
        "\n",
        "df.iloc[:,0] = pd.to_datetime(df.iloc[:,0], errors='coerce')\n",
        "df.set_index(df.columns[0], inplace=True)\n",
        "df.drop(columns=df.columns[0], inplace=True)\n",
        "diff.iloc[:,0] = pd.to_datetime(diff.iloc[:,0], errors='coerce')\n",
        "diff.set_index(diff.columns[0], inplace=True)\n",
        "merged_df = df.merge(diff, left_index=True, right_index=True, how='inner')\n",
        "d=merged_df.drop('close',axis=1, inplace=False)\n",
        "train_size = int(len(df) * 0.8)\n",
        "trainset,testset = a['close'][:train_size],a['close'][train_size:]\n",
        "exog = d\n",
        "arimax = SARIMAX(a['close'], exog=exog, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0))\n",
        "model = arimax.fit()\n",
        "prediction = model.predict(start=0, end=-1, exog=exog)\n",
        "residuals = a['close'] - prediction\n",
        "residuals_df = pd.DataFrame({'Residuals': residuals})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNgWLde7nlN1",
        "outputId": "305c1d44-0c22-4aeb-e54e-e7a5c0592940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
            "  return Index(sequences[0], name=names)\n",
            "<ipython-input-79-42c7bf8d24a1>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(columns=df.columns[0], inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
            "  return Index(sequences[0], name=names)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(residuals_df) * 0.8)\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "merged_df = df.merge(residuals_df, left_index=True, right_index=True, how='inner')\n",
        "d=merged_df.drop('Residuals',axis=1, inplace=False)\n",
        "X_train,X_test = d[:train_size], d[train_size:]\n",
        "Y_train,Y_test = merged_df['Residuals'][:train_size], merged_df['Residuals'][train_size:]\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)  # Convert DataFrame to tensor\n",
        "Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.float32)  # Convert Series to tensor\n"
      ],
      "metadata": {
        "id": "K5m82JIZntWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.tune import choice\n",
        "from ray.tune import uniform\n",
        "from ray.tune import uniform"
      ],
      "metadata": {
        "id": "YzF31GninG6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import train #import train to get train.report instead of keras integrations"
      ],
      "metadata": {
        "id": "4oB79g2NmGNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[all]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_-Agy6cgUhX",
        "outputId": "7bcdcf25-cfe5-4182-e7e1-ec3477cb2bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray[all]\n",
            "  Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[all]) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[all]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[all]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[all]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[all]) (2.32.3)\n",
            "Collecting gymnasium==1.0.0 (from ray[all])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (3.11.10)\n",
            "Collecting starlette (from ray[all])\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (2.10.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ray[all]) (13.9.4)\n",
            "Collecting fastapi (from ray[all])\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from ray[all]) (0.24.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (2.2.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from ray[all]) (0.1.8)\n",
            "Requirement already satisfied: pyOpenSSL in /usr/local/lib/python3.10/dist-packages (from ray[all]) (24.2.1)\n",
            "Collecting lz4 (from ray[all])\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[all]) (2024.10.0)\n",
            "Collecting opencensus (from ray[all])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.13.1)\n",
            "Collecting uvicorn[standard] (from ray[all])\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[all])\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.28.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[all])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[all])\n",
            "  Downloading virtualenv-20.28.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from ray[all])\n",
            "  Downloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting aiohttp-cors (from ray[all])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.68.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.26.4)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[all]) (7.0.5)\n",
            "Collecting colorful (from ray[all])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting watchfiles (from ray[all])\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.10/dist-packages (from ray[all]) (1.28.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (0.21.1)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[all]) (17.0.0)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from ray[all]) (0.15.1)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (from ray[all]) (12.2.0)\n",
            "Collecting memray (from ray[all])\n",
            "  Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==1.0.0->ray[all]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==1.0.0->ray[all]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==1.0.0->ray[all])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (2.4.4)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[all]) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[all]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[all]) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[all]) (2.27.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[all])\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[all]) (4.3.6)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x->ray[all]) (0.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->ray[all]) (3.7.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[all]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[all]) (0.22.3)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from memray->ray[all]) (3.1.4)\n",
            "Collecting textual>=0.41.0 (from memray->ray[all])\n",
            "  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ray[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ray[all]) (2.18.0)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[all]) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[all]) (2.19.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->ray[all]) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->ray[all]) (8.5.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.29.0 (from opentelemetry-exporter-otlp->ray[all])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.29.0 (from opentelemetry-exporter-otlp->ray[all])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.29.0->opentelemetry-exporter-otlp->ray[all]) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc==1.29.0->opentelemetry-exporter-otlp->ray[all])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc==1.29.0->opentelemetry-exporter-otlp->ray[all])\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk (from ray[all])\n",
            "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray[all])\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-api (from ray[all])\n",
            "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-sdk->ray[all])\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[all]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[all]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[all]) (2024.8.30)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL->ray[all]) (43.0.3)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[all]) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[all]) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[all]) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[all]) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[all]) (0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[all]) (1.17.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->ray[all]) (1.5.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]; extra == \"all\"->ray[all]) (0.14.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]; extra == \"all\"->ray[all])\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]; extra == \"all\"->ray[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]; extra == \"all\"->ray[all])\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]; extra == \"all\"->ray[all]) (14.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[all]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[all]) (1.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL->ray[all]) (1.17.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (2.27.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->ray[all]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->memray->ray[all]) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ray[all]) (0.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL->ray[all]) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (4.9)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[all]) (0.4.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[all]) (2.0.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[all]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[all]) (0.6.1)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.28.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading textual-1.0.0-py3-none-any.whl (660 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-spy, opencensus-context, farama-notifications, distlib, colorful, virtualenv, uvloop, uvicorn, python-dotenv, protobuf, lz4, httptools, gymnasium, watchfiles, tensorboardX, starlette, opentelemetry-proto, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, fastapi, textual, ray, opentelemetry-sdk, opencensus, aiohttp-cors, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, memray, opentelemetry-exporter-otlp\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.28.2\n",
            "    Uninstalling opentelemetry-api-1.28.2:\n",
            "      Successfully uninstalled opentelemetry-api-1.28.2\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.49b2\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.49b2:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.49b2\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.28.2\n",
            "    Uninstalling opentelemetry-sdk-1.28.2:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.28.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 colorful-0.5.6 distlib-0.3.9 farama-notifications-0.0.4 fastapi-0.115.6 gymnasium-1.0.0 httptools-0.6.4 lz4-4.3.3 memray-1.15.0 opencensus-0.11.4 opencensus-context-0.1.3 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-exporter-otlp-proto-http-1.29.0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 protobuf-5.29.1 py-spy-0.4.0 python-dotenv-1.0.1 ray-2.40.0 starlette-0.41.3 tensorboardX-2.6.2.2 textual-1.0.0 uvicorn-0.32.1 uvloop-0.21.0 virtualenv-20.28.0 watchfiles-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdvIKUZMx2Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95502662-23cf-4e68-a9c6-aea53ec7c6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+\n",
            "| Configuration for experiment     exp                   |\n",
            "+--------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator |\n",
            "| Scheduler                        FIFOScheduler         |\n",
            "| Number of trials                 1                     |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/exp\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-12-13_19-35-39_157175_590/artifacts/2024-12-13_21-44-14/exp/driver_artifacts`\n",
            "\n",
            "Trial status: 1 PENDING\n",
            "Current time: 2024-12-13 21:44:14. Total running time: 0s\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+------------------------------------+\n",
            "| Trial name                status   |\n",
            "+------------------------------------+\n",
            "| train_model_658fa_00000   PENDING  |\n",
            "+------------------------------------+\n",
            "\n",
            "Trial train_model_658fa_00000 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_658fa_00000 config             |\n",
            "+--------------------------------------------------+\n",
            "| activation                                  tanh |\n",
            "| batch_size                                     4 |\n",
            "| dropout_prob                             0.21308 |\n",
            "| initializer                               xavier |\n",
            "| learning_rate                            0.03567 |\n",
            "| n_hidden                                       5 |\n",
            "| num_epochs                                     5 |\n",
            "| optimizer                                   adam |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-13 21:44:27,674\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/exp' in 0.0046s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_658fa_00000 finished iteration 1 at 2024-12-13 21:44:27. Total running time: 12s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_658fa_00000 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         11.2884 |\n",
            "| time_total_s                             11.2884 |\n",
            "| training_iteration                             1 |\n",
            "| MSE                                      4.82523 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_658fa_00000 completed after 1 iterations at 2024-12-13 21:44:27. Total running time: 12s\n",
            "\n",
            "Trial status: 1 TERMINATED\n",
            "Current time: 2024-12-13 21:44:27. Total running time: 12s\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 658fa_00000 with MSE=4.825228982333895 and params={'n_hidden': 5, 'dropout_prob': 0.21307617072616686, 'learning_rate': 0.03567430187528342, 'batch_size': 4, 'num_epochs': 5, 'optimizer': 'adam', 'initializer': 'xavier', 'activation': 'tanh'}\n",
            "+----------------------------------------------------------------------------+\n",
            "| Trial name                status         iter     total time (s)       MSE |\n",
            "+----------------------------------------------------------------------------+\n",
            "| train_model_658fa_00000   TERMINATED        1            11.2884   4.82523 |\n",
            "+----------------------------------------------------------------------------+\n",
            "\n",
            "Best configuration: {'n_hidden': 5, 'dropout_prob': 0.21307617072616686, 'learning_rate': 0.03567430187528342, 'batch_size': 4, 'num_epochs': 5, 'optimizer': 'adam', 'initializer': 'xavier', 'activation': 'tanh'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "#wrapped to take config dictionary\n",
        "def train_model(config):\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "    class FC2Layer(nn.Module):\n",
        "      def __init__(self, input_size, n_hidden, output_size, dropout_prob, activation):\n",
        "        super(FC2Layer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.dropout_prob = dropout_prob\n",
        "        if activation =='relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        else :\n",
        "            self.activation = nn.ReLU()\n",
        "            print(\"Activation function not implemented, using default ReLU\")\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, n_hidden),\n",
        "            self.activation,\n",
        "            nn.Dropout(p=dropout_prob),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            self.activation,\n",
        "            nn.Dropout(p=dropout_prob),\n",
        "            nn.Linear(n_hidden, output_size)\n",
        "        )\n",
        "\n",
        "      def forward(self, x):\n",
        "          return self.network(x)\n",
        "\n",
        "\n",
        "    # Synthetic data for example\n",
        "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)  # Convert DataFrame to tensor\n",
        "    Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    if len(Y_train_tensor.shape) == 1:\n",
        "      Y_train_tensor = Y_train_tensor.unsqueeze(1)\n",
        "\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "    Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.float32)\n",
        "    if len(Y_test_tensor.shape) == 1:\n",
        "      Y_test_tensor = Y_test_tensor.unsqueeze(1)\n",
        "    test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = FC2Layer(\n",
        "        input_size=4,\n",
        "        n_hidden=int(config[\"n_hidden\"]),\n",
        "        output_size=1,\n",
        "        dropout_prob=config[\"dropout_prob\"],\n",
        "        activation=config['activation']\n",
        "    )\n",
        "\n",
        "    # Apply weight initializer\n",
        "    if config[\"initializer\"] == \"xavier\":\n",
        "        def xavier_init(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "        model.apply(xavier_init)\n",
        "    elif config[\"initializer\"] == \"normal\":\n",
        "        def normal_init(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "        model.apply(normal_init)\n",
        "\n",
        "    # Select optimizer\n",
        "    if config[\"optimizer\"] == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    elif config[\"optimizer\"] == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
        "    elif config[\"optimizer\"] == \"rmsprop\":\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(int(config[\"num_epochs\"])):\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Testing loop\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "    mse_loss = test_loss / len(test_loader)\n",
        "\n",
        "    # Report result to Ray Tune\n",
        "    train.report({\"MSE\": mse_loss})\n",
        "\n",
        "# Define search space\n",
        "search_space = {\n",
        "    \"n_hidden\": np.random.choice([2, 5, 10]),\n",
        "    \"dropout_prob\": np.random.uniform(0.1, 0.5),\n",
        "    \"learning_rate\": np.random.uniform(0.001, 0.1),\n",
        "    \"batch_size\": np.random.randint(2,10),\n",
        "    \"num_epochs\": np.random.choice([2, 5, 10]),\n",
        "    \"optimizer\": np.random.choice([\"adam\", \"sgd\", \"rmsprop\"]),\n",
        "    \"initializer\": np.random.choice([\"xavier\", \"normal\"]),\n",
        "    'activation':np.random.choice([\"tanh\", \"sigmoid\", 'relu'])\n",
        "}\n",
        "\n",
        "# Run the search\n",
        "analysis_grid = tune.run(\n",
        "    train_model,\n",
        "    name=\"exp\",\n",
        "    metric=\"MSE\",\n",
        "    mode=\"min\",\n",
        "    stop={\"MSE\": 2},\n",
        "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
        "    config=search_space,\n",
        ")\n",
        "\n",
        "# Best configuration\n",
        "best_grid = analysis_grid.best_config\n",
        "print(\"Best configuration:\", best_grid)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config={\"n_hidden\": 2,\n",
        "    \"dropout_prob\": .1,\n",
        "    \"learning_rate\": .001,\n",
        "    \"batch_size\": 4,\n",
        "    \"num_epochs\": 5,\n",
        "    \"optimizer\": 'adam',\n",
        "    \"initializer\": 'xavier',\n",
        "    \"activation\":'tanh'}\n",
        "train_model(config)"
      ],
      "metadata": {
        "id": "eRy4AeNPhjpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFyNtoeOyrjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12299a42-620b-4317-a0e4-ba0e8e694478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+\n",
            "| Configuration for experiment     hyperband_exp         |\n",
            "+--------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator |\n",
            "| Scheduler                        HyperBandScheduler    |\n",
            "| Number of trials                 1                     |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/hyperband_exp\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-12-13_19-35-39_157175_590/artifacts/2024-12-13_21-56-07/hyperband_exp/driver_artifacts`\n",
            "\n",
            "Trial status: 1 PENDING\n",
            "Current time: 2024-12-13 21:56:07. Total running time: 0s\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+------------------------------------+\n",
            "| Trial name                status   |\n",
            "+------------------------------------+\n",
            "| train_model_0ea08_00000   PENDING  |\n",
            "+------------------------------------+\n",
            "\n",
            "Trial train_model_0ea08_00000 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_0ea08_00000 config             |\n",
            "+--------------------------------------------------+\n",
            "| activation                                  tanh |\n",
            "| batch_size                                     4 |\n",
            "| dropout_prob                             0.21308 |\n",
            "| initializer                               xavier |\n",
            "| learning_rate                            0.03567 |\n",
            "| n_hidden                                       5 |\n",
            "| num_epochs                                     5 |\n",
            "| optimizer                                   adam |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-13 21:56:22,327\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/hyperband_exp' in 0.0044s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_0ea08_00000 finished iteration 1 at 2024-12-13 21:56:22. Total running time: 14s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_0ea08_00000 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         12.7985 |\n",
            "| time_total_s                             12.7985 |\n",
            "| training_iteration                             1 |\n",
            "| MSE                                      4.83112 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_0ea08_00000 completed after 1 iterations at 2024-12-13 21:56:22. Total running time: 14s\n",
            "\n",
            "Trial status: 1 TERMINATED\n",
            "Current time: 2024-12-13 21:56:22. Total running time: 14s\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 0ea08_00000 with MSE=4.8311213830226585 and params={'n_hidden': 5, 'dropout_prob': 0.21307617072616686, 'learning_rate': 0.03567430187528342, 'batch_size': 4, 'num_epochs': 5, 'optimizer': 'adam', 'initializer': 'xavier', 'activation': 'tanh'}\n",
            "+----------------------------------------------------------------------------+\n",
            "| Trial name                status         iter     total time (s)       MSE |\n",
            "+----------------------------------------------------------------------------+\n",
            "| train_model_0ea08_00000   TERMINATED        1            12.7985   4.83112 |\n",
            "+----------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hyperband_scheduler = HyperBandScheduler(\n",
        "     # Maximize the mean_accuracy metric\n",
        "    max_t=100,  # Maximum resource allocation (e.g., epochs)\n",
        "    # Minimum resource allocation before stopping\n",
        ")\n",
        "\n",
        "# Run the experiment with HyperBand\n",
        "analysis_hyperband = tune.run(\n",
        "    train_model,\n",
        "    name=\"hyperband_exp\",\n",
        "    metric=\"MSE\",\n",
        "    mode=\"min\",\n",
        "    resources_per_trial={\n",
        "         \"cpu\": 1, \"gpu\": 1\n",
        "    },\n",
        "    config=search_space,\n",
        "    scheduler=hyperband_scheduler  # Add the HyperBand scheduler\n",
        ")\n",
        "\n",
        "best_hyperband = analysis_hyperband.best_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1z-OrXhyreZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf034ae-df23-4c5c-8e32-2a5e13b162a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_hidden': 5, 'dropout_prob': 0.21307617072616686, 'learning_rate': 0.03567430187528342, 'batch_size': 4, 'num_epochs': 5, 'optimizer': 'adam', 'initializer': 'xavier', 'activation': 'tanh'}\n"
          ]
        }
      ],
      "source": [
        "print(best_hyperband)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEwRm1E0yrX1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IkyUhl1g0JWf",
        "KM581eVgz_Uj",
        "ryPA9dEA2T-K",
        "TGBA1mcLjvPj",
        "XsQwa3u9AYOS",
        "jDQBxMVLfaFK"
      ],
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}